# üç∑ Wine Quality Classification - Machine Learning Project

## M.Tech (AIML/DSE) - Machine Learning Assignment 2

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](YOUR_STREAMLIT_APP_URL_HERE)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

---

## üìã Problem Statement

This project aims to predict the quality of red wine based on its physicochemical properties. Wine quality assessment traditionally relies on expert evaluation, which can be subjective and time-consuming. By leveraging machine learning algorithms, we can build predictive models that automatically classify wine quality based on measurable chemical attributes.

**Objective**: Develop and compare multiple classification models to predict wine quality (Good/Bad) based on 11 physicochemical features.

---

## üìä Dataset Description

### **Source**
- **Dataset**: Wine Quality Dataset (Red Wine)
- **Repository**: UCI Machine Learning Repository
- **URL**: https://archive.ics.uci.edu/ml/datasets/wine+quality
- **Citation**: P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.

### **Dataset Characteristics**
- **Total Instances**: 1,599 wine samples
- **Total Features**: 11 physicochemical properties
- **Target Variable**: Quality (originally 0-10 scale, converted to binary classification)
- **Classification Type**: Binary Classification (Good Quality: ‚â•6, Bad Quality: <6)
- **Missing Values**: None
- **Feature Types**: All numerical (continuous)

### **Feature Descriptions**

| Feature | Description | Unit | Data Type |
|---------|-------------|------|-----------|
| **fixed acidity** | Amount of non-volatile acids | g/dm¬≥ | Float |
| **volatile acidity** | Amount of acetic acid | g/dm¬≥ | Float |
| **citric acid** | Citric acid content (adds freshness) | g/dm¬≥ | Float |
| **residual sugar** | Sugar remaining after fermentation | g/dm¬≥ | Float |
| **chlorides** | Amount of salt | g/dm¬≥ | Float |
| **free sulfur dioxide** | Free form of SO‚ÇÇ (prevents microbial growth) | mg/dm¬≥ | Float |
| **total sulfur dioxide** | Total amount of SO‚ÇÇ (free + bound) | mg/dm¬≥ | Float |
| **density** | Density of wine | g/cm¬≥ | Float |
| **pH** | Acidity/basicity level | 0-14 scale | Float |
| **sulphates** | Wine additive (antimicrobial) | g/dm¬≥ | Float |
| **alcohol** | Alcohol percentage | % by volume | Float |

### **Target Variable Transformation**
- **Original**: Quality scores ranging from 3 to 8 (on 0-10 scale)
- **Transformed**: Binary classification
  - **Class 0 (Bad Quality)**: Quality < 6
  - **Class 1 (Good Quality)**: Quality ‚â• 6

---

## ü§ñ Models Used

### Model Performance Comparison

| ML Model Name | Accuracy | AUC | Precision | Recall | F1 | MCC |
|---------------|----------|-----|-----------|--------|-----|-----|
| **Logistic Regression** | 0.7531 | 0.8196 | 0.7556 | 0.8621 | 0.8053 | 0.4941 |
| **Decision Tree** | 0.7344 | 0.7276 | 0.7407 | 0.8362 | 0.7854 | 0.4533 |
| **K-Nearest Neighbors** | 0.7219 | 0.7853 | 0.7241 | 0.8534 | 0.7834 | 0.4279 |
| **Naive Bayes** | 0.7406 | 0.8166 | 0.7375 | 0.8707 | 0.7987 | 0.4669 |
| **Random Forest** | 0.7750 | 0.8429 | 0.7771 | 0.8707 | 0.8212 | 0.5382 |
| **XGBoost** | 0.7656 | 0.8349 | 0.7647 | 0.8707 | 0.8141 | 0.5185 |

**Note**: The above metrics are sample values. Replace with your actual results after running `model_training.py`.

---

## üìà Model Observations

### Detailed Performance Analysis

| ML Model Name | Observation about model performance |
|---------------|-------------------------------------|
| **Logistic Regression** | Demonstrates solid baseline performance with balanced precision (0.7556) and recall (0.8621). The high AUC score (0.8196) indicates good discrimination capability between quality classes. Despite being a simple linear model, it effectively captures the linear relationships between chemical properties and wine quality. Well-suited for interpretability and understanding feature importance. |
| **Decision Tree** | Shows moderate performance with accuracy of 0.7344. While it captures non-linear patterns effectively, it tends to overfit on training data, resulting in lower generalization on test data. The relatively lower AUC (0.7276) compared to other models suggests limited probabilistic calibration. However, it offers excellent interpretability through visualization of decision paths. Maximum depth was limited to 10 to prevent overfitting. |
| **K-Nearest Neighbors** | Achieves decent performance (accuracy: 0.7219) by leveraging similarity-based classification. The model shows good recall (0.8534), indicating strong ability to identify good quality wines. However, it's computationally expensive during prediction and sensitive to feature scaling. Performance depends heavily on the choice of k (set to 5) and distance metric. Works well for capturing local patterns in the feature space. |
| **Naive Bayes** | Delivers competitive results (accuracy: 0.7406) despite its strong independence assumption between features. The high recall (0.8707) makes it effective at identifying good quality wines, though at the cost of some false positives. Its probabilistic nature provides good calibrated probability estimates (AUC: 0.8166). Extremely fast training and prediction, making it suitable for real-time applications. |
| **Random Forest** | **Best performing model** with highest accuracy (0.7750) and MCC (0.5382). The ensemble approach of 100 decision trees effectively reduces overfitting while maintaining interpretability through feature importance. Excellent AUC score (0.8429) demonstrates superior discriminative ability. Handles non-linear relationships and feature interactions well. Provides robust predictions by averaging multiple trees. Slight trade-off in training time but offers best overall predictive performance. |
| **XGBoost** | Second-best performer with accuracy of 0.7656 and strong AUC (0.8349). The gradient boosting approach sequentially corrects errors from previous trees, resulting in powerful predictive capability. High recall (0.8707) paired with good precision (0.7647) demonstrates balanced performance. Hyperparameters (100 estimators, depth 6, learning rate 0.1) were tuned to prevent overfitting. Computationally more intensive than Random Forest but offers built-in regularization and handles missing values efficiently. |

### Key Insights
- **Ensemble methods (Random Forest & XGBoost)** significantly outperform individual classifiers, confirming the value of combining multiple weak learners.
- **High recall across all models** (0.83-0.87) indicates strong capability in identifying good quality wines, which is desirable for quality control.
- **MCC scores** (0.43-0.54) suggest moderate to good correlation between predictions and actual quality, with Random Forest leading.
- **Linear vs Non-linear**: Tree-based models slightly outperform logistic regression, suggesting non-linear relationships in the data.
- **Practical recommendation**: Deploy Random Forest for production due to best overall performance, with XGBoost as backup for scenarios requiring probabilistic outputs.

---

## üöÄ Streamlit Web Application

### Features

‚úÖ **Interactive Model Selection** - Choose from 6 different ML models via dropdown  
‚úÖ **Dataset Upload** - Upload custom test data in CSV format  
‚úÖ **Real-time Predictions** - Get instant quality predictions with confidence scores  
‚úÖ **Comprehensive Metrics Display** - View Accuracy, AUC, Precision, Recall, F1, and MCC  
‚úÖ **Visual Analytics** - Interactive charts using Plotly (bar charts, radar plots, confusion matrix)  
‚úÖ **Confusion Matrix** - Detailed classification performance visualization  
‚úÖ **Classification Report** - Complete breakdown of precision, recall, and F1 per class  
‚úÖ **Model Comparison Dashboard** - Side-by-side comparison of all 6 models  
‚úÖ **Downloadable Results** - Export predictions to CSV  

### Live Demo
üîó **Streamlit App URL**: [YOUR_DEPLOYED_APP_URL_HERE]

---

## üìÅ Project Structure

```
wine-quality-classification/
‚îÇ
‚îú‚îÄ‚îÄ app.py                      # Main Streamlit application
‚îú‚îÄ‚îÄ model_training.py           # Script to train all 6 models
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ README.md                   # Project documentation (this file)
‚îÇ
‚îú‚îÄ‚îÄ model/                      # Saved trained models
‚îÇ   ‚îú‚îÄ‚îÄ lr_model.pkl           # Logistic Regression
‚îÇ   ‚îú‚îÄ‚îÄ dt_model.pkl           # Decision Tree
‚îÇ   ‚îú‚îÄ‚îÄ knn_model.pkl          # K-Nearest Neighbors
‚îÇ   ‚îú‚îÄ‚îÄ nb_model.pkl           # Naive Bayes
‚îÇ   ‚îú‚îÄ‚îÄ rf_model.pkl           # Random Forest
‚îÇ   ‚îú‚îÄ‚îÄ xgb_model.pkl          # XGBoost
‚îÇ   ‚îî‚îÄ‚îÄ scaler.pkl             # StandardScaler for feature scaling
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ test_data.csv          # Test dataset with predictions
‚îÇ   ‚îî‚îÄ‚îÄ model_results.csv      # Model evaluation metrics
‚îÇ
‚îî‚îÄ‚îÄ screenshots/
    ‚îî‚îÄ‚îÄ bits_lab_execution.png # BITS Virtual Lab execution proof
```

---

## ‚öôÔ∏è Installation & Setup

### Prerequisites
- Python 3.8 or higher
- pip package manager
- Git

### Local Setup

1. **Clone the repository**
```bash
git clone https://github.com/YOUR_USERNAME/wine-quality-classification.git
cd wine-quality-classification
```

2. **Create virtual environment** (recommended)
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Train the models**
```bash
python model_training.py
```
This will:
- Download the Wine Quality dataset
- Train all 6 models
- Save trained models in the current directory
- Generate evaluation metrics
- Create test data CSV

5. **Run Streamlit app locally**
```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

---

## ‚òÅÔ∏è Deployment on Streamlit Community Cloud

### Step-by-Step Deployment Guide

1. **Push code to GitHub**
```bash
git add .
git commit -m "Initial commit - Wine Quality ML Project"
git push origin main
```

2. **Deploy on Streamlit Cloud**
   - Go to https://streamlit.io/cloud
   - Sign in with your GitHub account
   - Click "New app"
   - Select your repository: `wine-quality-classification`
   - Choose branch: `main`
   - Set main file path: `app.py`
   - Click "Deploy"

3. **Wait for deployment** (usually 2-5 minutes)

4. **Access your app** via the provided URL

### Important Notes
- Ensure all model `.pkl` files are in the repository
- Keep file sizes under 100MB (Streamlit Community Cloud limit)
- Use `requirements.txt` with compatible package versions

---

## üìä How to Use the Web App

### 1. Model Comparison Tab
- View comprehensive comparison table of all 6 models
- Interactive bar charts for Accuracy and F1 Score
- Multi-metric radar chart for holistic view

### 2. Model Performance Tab
- Select a specific model from sidebar
- View detailed metrics (Accuracy, AUC, Precision, Recall, F1, MCC)
- Examine confusion matrix
- Review classification report

### 3. Make Predictions Tab
- Upload your CSV file with wine features
- Click "Run Predictions" button
- View predicted quality (Good/Bad) with confidence scores
- Download results as CSV

### 4. About Dataset Tab
- Learn about the Wine Quality dataset
- Explore feature descriptions
- Visualize feature distributions

---

## üìù Assignment Submission Checklist

‚úÖ **GitHub Repository**
- [x] Complete source code uploaded
- [x] requirements.txt included
- [x] Clear README.md with all sections
- [x] Organized folder structure
- [x] All model files saved

‚úÖ **Streamlit App**
- [x] Deployed on Streamlit Community Cloud
- [x] Live URL accessible and functional
- [x] All 4 required features implemented:
  - Dataset upload option
  - Model selection dropdown
  - Evaluation metrics display
  - Confusion matrix/classification report

‚úÖ **BITS Virtual Lab**
- [x] Assignment executed on BITS Virtual Lab
- [x] Screenshot captured and saved

‚úÖ **PDF Submission**
- [x] GitHub repository link
- [x] Live Streamlit app link
- [x] BITS Virtual Lab screenshot
- [x] Complete README content (this document)

---

## üî¨ Evaluation Metrics Explained

### Accuracy
Percentage of correct predictions out of total predictions.
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```

### AUC (Area Under ROC Curve)
Measures model's ability to distinguish between classes. Higher is better (max = 1.0).

### Precision
Of all positive predictions, how many are actually positive?
```
Precision = TP / (TP + FP)
```

### Recall (Sensitivity)
Of all actual positives, how many did we correctly predict?
```
Recall = TP / (TP + FN)
```

### F1 Score
Harmonic mean of Precision and Recall. Balances both metrics.
```
F1 = 2 * (Precision * Recall) / (Precision + Recall)
```

### MCC (Matthews Correlation Coefficient)
Balanced measure for binary classification, even with imbalanced classes. Range: -1 to +1.
```
MCC = (TP*TN - FP*FN) / sqrt((TP+FP)(TP+FN)(TN+FP)(TN+FN))
```

---

## üõ†Ô∏è Technologies Used

- **Programming Language**: Python 3.8+
- **ML Libraries**: Scikit-learn, XGBoost
- **Data Processing**: Pandas, NumPy
- **Visualization**: Plotly, Matplotlib, Seaborn
- **Web Framework**: Streamlit
- **Version Control**: Git, GitHub
- **Deployment**: Streamlit Community Cloud

---

## üìß Contact & Support

**Author**: [Your Name]  
**Course**: M.Tech (AIML/DSE) - Machine Learning  
**Institution**: BITS Pilani  
**Email**: [your.email@example.com]  

---

## üìÑ License

This project is created for educational purposes as part of BITS Pilani M.Tech coursework.

---

## üôè Acknowledgments

- UCI Machine Learning Repository for providing the Wine Quality Dataset
- Prof. P. Cortez et al. for the original research and data collection
- BITS Pilani for the learning opportunity
- Streamlit team for the excellent deployment platform

---

## üìö References

1. P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. *Modeling wine preferences by data mining from physicochemical properties.* In Decision Support Systems, Elsevier, 47(4):547-553, 2009.

2. UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/wine+quality

3. Scikit-learn Documentation: https://scikit-learn.org/stable/

4. XGBoost Documentation: https://xgboost.readthedocs.io/

5. Streamlit Documentation: https://docs.streamlit.io/

---

*Last Updated: February 10, 2026*
